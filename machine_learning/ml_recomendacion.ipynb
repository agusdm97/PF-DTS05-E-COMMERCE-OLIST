{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 align=center>Modelo de recomendación con filtro colaborativo.</h2>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Importamos librerías**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow.python'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39msqlalchemy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39msql\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtf\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpreprocessing\u001b[39;00m \u001b[39mimport\u001b[39;00m MinMaxScaler\n\u001b[0;32m      5\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\guill\\OneDrive\\Documentos\\Proyecto Grupal\\PF-DTS05-E-COMMERCE-OLIST\\venv\\lib\\site-packages\\tensorflow\\__init__.py:37\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39msys\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39m_sys\u001b[39;00m\n\u001b[0;32m     35\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtyping\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39m_typing\u001b[39;00m\n\u001b[1;32m---> 37\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtools\u001b[39;00m \u001b[39mimport\u001b[39;00m module_util \u001b[39mas\u001b[39;00m _module_util\n\u001b[0;32m     38\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutil\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlazy_loader\u001b[39;00m \u001b[39mimport\u001b[39;00m LazyLoader \u001b[39mas\u001b[39;00m _LazyLoader\n\u001b[0;32m     40\u001b[0m \u001b[39m# Make sure code inside the TensorFlow codebase can use tf2.enabled() at import.\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow.python'"
     ]
    }
   ],
   "source": [
    "\n",
    "import sqlalchemy as sql\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.- Preparamos los datos para el modelo**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos la conexion con la base de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = sql.create_engine(\n",
    "    \"mysql+pymysql://root:password@localhost:3307/data_warehouse_olist?charset=utf8mb4\"\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos dataframe con la información necesaria desde mysql. Incluimos los datos de id de clientes, id de productos y las calificaciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = pd.read_sql(sql=\"\"\"\n",
    "    SELECT customers.unique_id, order_items.product_id,  order_reviews.score\n",
    "    FROM order_items\n",
    "    LEFT JOIN orders ON (order_items.order_id = orders.order_id)\n",
    "    LEFT JOIN customers ON (orders.customer_id = customers.customer_id)\n",
    "    RIGHT JOIN order_reviews ON (orders.order_id = order_reviews.order_id);\"\"\", con=engine)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Descartamos duplicados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined.drop_duplicates(['unique_id','product_id'],inplace= True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Porcederemos a preparar los datos para crear la matriz de usuario-producto. \n",
    "\n",
    "Para realizarla se tuvo en cuenta el hecho de que existe gran numero de clientes y productos, pero poca interacción entre ellos. En consecuencia, se procedió a filtrar admitiendo solo aquellos clientes que habian realizado mas de tres calificaciones y productos que fueron valorados por lo menos en cinco ocasiones. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos dos dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_products = combined[['product_id', 'score']]\n",
    "df_customer = combined[['unique_id', 'score']]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aplicamos el filtro sobre ellos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_products= df_products.groupby(\"product_id\").aggregate({\"score\":\"count\"})\n",
    "df_products.reset_index(inplace=True)\n",
    "df_products.rename(columns={\"score\":\"product_count\"},inplace=True)\n",
    "df_products = df_products[df_products[\"product_count\"] > 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_customer= df_customer.groupby(\"unique_id\").aggregate({\"score\":\"count\"})\n",
    "df_customer.reset_index(inplace=True)\n",
    "df_customer.rename(columns={\"score\":\"customer_count\"}, inplace= True)\n",
    "df_customer = df_customer[df_customer[\"customer_count\"] > 2]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los utilizamos como filtro para el dataframe principal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_ = combined[\"product_id\"].isin(df_products[\"product_id\"]) & combined[\"unique_id\"].isin(df_customer[\"unique_id\"])\n",
    "combined = combined[filter_]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = pd.merge(left= combined, right = df_customer, on = 'unique_id',  how = 'left')\n",
    "combined = pd.merge(left= combined, right = df_products, on = 'product_id',  how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>score</th>\n",
       "      <th>customer_count</th>\n",
       "      <th>product_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>432aa6200ee9673be90863a912dc91dc</td>\n",
       "      <td>bed9b7934576c9ba61b6ba6f3babc698</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fd8ccc89be43894d2553494c71a61fd8</td>\n",
       "      <td>8ae935cab2de3f74f4960de6ee604f90</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a1a374f4c131638dc698c76bebd11769</td>\n",
       "      <td>8a443635fdf9759915c9be5be2e3b862</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a1a374f4c131638dc698c76bebd11769</td>\n",
       "      <td>87d780fa7d2cf3710aa02dc4ca8db985</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>d75acd4c5b7b4dfd32b9d9172b195419</td>\n",
       "      <td>d0fe4295267f15ccaceac4fb233d8c9a</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1014</th>\n",
       "      <td>dd8c09f1b309c9ffc302c745550a9ff3</td>\n",
       "      <td>372645c7439f9661fbbacfd129aa92ec</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1015</th>\n",
       "      <td>dd8c09f1b309c9ffc302c745550a9ff3</td>\n",
       "      <td>525947dbe3304ac32bf51602f9557c12</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1016</th>\n",
       "      <td>0aef107040099c08391f73e81821bbac</td>\n",
       "      <td>88c20c5a22f2ca169af8cfc2df00a7a2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1017</th>\n",
       "      <td>0aef107040099c08391f73e81821bbac</td>\n",
       "      <td>3625fbaf8284047185fb0351f2f84ae3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1018</th>\n",
       "      <td>58703c8104494f333026acd373ca9027</td>\n",
       "      <td>4dddd45aa241530edb5412e8846361fa</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1019 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             unique_id                        product_id  \\\n",
       "0     432aa6200ee9673be90863a912dc91dc  bed9b7934576c9ba61b6ba6f3babc698   \n",
       "1     fd8ccc89be43894d2553494c71a61fd8  8ae935cab2de3f74f4960de6ee604f90   \n",
       "2     a1a374f4c131638dc698c76bebd11769  8a443635fdf9759915c9be5be2e3b862   \n",
       "3     a1a374f4c131638dc698c76bebd11769  87d780fa7d2cf3710aa02dc4ca8db985   \n",
       "4     d75acd4c5b7b4dfd32b9d9172b195419  d0fe4295267f15ccaceac4fb233d8c9a   \n",
       "...                                ...                               ...   \n",
       "1014  dd8c09f1b309c9ffc302c745550a9ff3  372645c7439f9661fbbacfd129aa92ec   \n",
       "1015  dd8c09f1b309c9ffc302c745550a9ff3  525947dbe3304ac32bf51602f9557c12   \n",
       "1016  0aef107040099c08391f73e81821bbac  88c20c5a22f2ca169af8cfc2df00a7a2   \n",
       "1017  0aef107040099c08391f73e81821bbac  3625fbaf8284047185fb0351f2f84ae3   \n",
       "1018  58703c8104494f333026acd373ca9027  4dddd45aa241530edb5412e8846361fa   \n",
       "\n",
       "      score  customer_count  product_count  \n",
       "0         5               3              6  \n",
       "1         4               3              5  \n",
       "2         5               3             27  \n",
       "3         5               3             23  \n",
       "4         5               5             13  \n",
       "...     ...             ...            ...  \n",
       "1014      2               4             23  \n",
       "1015      2               4             10  \n",
       "1016      1               3             12  \n",
       "1017      1               3             13  \n",
       "1018      1               3              5  \n",
       "\n",
       "[1019 rows x 5 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique products 704\n",
      "Number of unique users 528\n"
     ]
    }
   ],
   "source": [
    "print('Number of unique products', combined['product_id'].nunique())\n",
    "print('Number of unique users', combined['unique_id'].nunique())\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalizamos la función de calificación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "combined['score'] = combined['score'].values.astype(float)\n",
    "score_scaled = pd.DataFrame(scaler.fit_transform(combined['score'].values.reshape(-1,1)))\n",
    "combined['score'] = score_scaled"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos la matriz usuario-producto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = combined.drop_duplicates(['unique_id', 'product_id'])\n",
    "user_products_matrix = combined.pivot(index='unique_id', columns='product_id', values='score')\n",
    "user_products_matrix.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "#probable error\n",
    "users = user_products_matrix.index.tolist()\n",
    "products = user_products_matrix.columns.tolist()\n",
    "\n",
    "user_products_matrix = user_products_matrix.values"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "placeholder solo esta en V1, asi que lo importamos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configuramos alguno parametros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_input = combined['product_id'].nunique()\n",
    "num_hidden_1 = 10\n",
    "num_hidden_2 = 5\n",
    "\n",
    "X = tf.placeholder(tf.float64, [None, num_input])\n",
    "\n",
    "weights = {\n",
    "    'encoder_h1': tf.Variable(tf.random_normal([num_input, num_hidden_1], dtype=tf.float64)),\n",
    "    'encoder_h2': tf.Variable(tf.random_normal([num_hidden_1, num_hidden_2], dtype=tf.float64)),\n",
    "    'decoder_h1': tf.Variable(tf.random_normal([num_hidden_2, num_hidden_1], dtype=tf.float64)),\n",
    "    'decoder_h2': tf.Variable(tf.random_normal([num_hidden_1, num_input], dtype=tf.float64)),\n",
    "}\n",
    "\n",
    "biases = {\n",
    "    'encoder_b1': tf.Variable(tf.random_normal([num_hidden_1], dtype=tf.float64)),\n",
    "    'encoder_b2': tf.Variable(tf.random_normal([num_hidden_2], dtype=tf.float64)),\n",
    "    'decoder_b1': tf.Variable(tf.random_normal([num_hidden_1], dtype=tf.float64)),\n",
    "    'decoder_b2': tf.Variable(tf.random_normal([num_input], dtype=tf.float64)),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder(x):\n",
    "    layer_1 = tf.nn.sigmoid(tf.add(tf.matmul(x, weights['encoder_h1']), biases['encoder_b1']))\n",
    "    layer_2 = tf.nn.sigmoid(tf.add(tf.matmul(layer_1, weights['encoder_h2']), biases['encoder_b2']))\n",
    "    return layer_2\n",
    "\n",
    "def decoder(x):\n",
    "    layer_1 = tf.nn.sigmoid(tf.add(tf.matmul(x, weights['decoder_h1']), biases['decoder_b1']))\n",
    "    layer_2 = tf.nn.sigmoid(tf.add(tf.matmul(layer_1, weights['decoder_h2']), biases['decoder_b2']))\n",
    "    return layer_2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construimos el modelo y las predicciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_op = encoder(X)\n",
    "decoder_op = decoder(encoder_op)\n",
    "\n",
    "y_pred = decoder_op\n",
    "\n",
    "y_true = X"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Difinimos funciones de evaluación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.losses.mean_squared_error(y_true, y_pred)\n",
    "optimizer = tf.train.RMSPropOptimizer(0.03).minimize(loss)\n",
    "eval_x = tf.placeholder(tf.int32, )\n",
    "eval_y = tf.placeholder(tf.int32, )\n",
    "pre, pre_op = tf.metrics.precision(labels=eval_x, predictions=eval_y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inicializamos las variables y creamos un marco de datos vacíos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "local_init = tf.local_variables_initializer()\n",
    "pred_data = pd.DataFrame()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenamos. 50 epocas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 Loss: 0.36914319296677905\n",
      "epoch: 2 Loss: 0.36901794870694477\n",
      "epoch: 3 Loss: 0.36884625256061554\n",
      "epoch: 4 Loss: 0.36861097315947217\n",
      "epoch: 5 Loss: 0.36828866104284924\n",
      "epoch: 6 Loss: 0.3678473581870397\n",
      "epoch: 7 Loss: 0.36724352339903515\n",
      "epoch: 8 Loss: 0.3664180636405945\n",
      "epoch: 9 Loss: 0.3652910590171814\n",
      "epoch: 10 Loss: 0.3637548585732778\n",
      "epoch: 11 Loss: 0.3616654922564824\n",
      "epoch: 12 Loss: 0.3588319420814514\n",
      "epoch: 13 Loss: 0.35500313341617584\n",
      "epoch: 14 Loss: 0.3498541017373403\n",
      "epoch: 15 Loss: 0.3429752637942632\n",
      "epoch: 16 Loss: 0.33387985825538635\n",
      "epoch: 17 Loss: 0.32205556829770404\n",
      "epoch: 18 Loss: 0.30721646547317505\n",
      "epoch: 19 Loss: 0.2902962913115819\n",
      "epoch: 20 Loss: 0.2732970863580704\n",
      "epoch: 21 Loss: 0.256226879854997\n",
      "epoch: 22 Loss: 0.23706882695357004\n",
      "epoch: 23 Loss: 0.21355329205592474\n",
      "epoch: 24 Loss: 0.18378194669882456\n",
      "epoch: 25 Loss: 0.14623686422904333\n",
      "epoch: 26 Loss: 0.1016488845149676\n",
      "epoch: 27 Loss: 0.05983076182504495\n",
      "epoch: 28 Loss: 0.033700027503073215\n",
      "epoch: 29 Loss: 0.021818057013054688\n",
      "epoch: 30 Loss: 0.0161876636557281\n",
      "epoch: 31 Loss: 0.01305531213680903\n",
      "epoch: 32 Loss: 0.010495565365999937\n",
      "epoch: 33 Loss: 0.008243764052167535\n",
      "epoch: 34 Loss: 0.0070417166377107305\n",
      "epoch: 35 Loss: 0.006687779678031802\n",
      "epoch: 36 Loss: 0.006493560193727414\n",
      "epoch: 37 Loss: 0.006346913054585457\n",
      "epoch: 38 Loss: 0.00546134845353663\n",
      "epoch: 39 Loss: 0.004178623319603503\n",
      "epoch: 40 Loss: 0.003992456515940527\n",
      "epoch: 41 Loss: 0.003928609890863299\n",
      "epoch: 42 Loss: 0.003894239974518617\n",
      "epoch: 43 Loss: 0.003872632204244534\n",
      "epoch: 44 Loss: 0.003857893714060386\n",
      "epoch: 45 Loss: 0.0038473368622362614\n",
      "epoch: 46 Loss: 0.0038395465817302465\n",
      "epoch: 47 Loss: 0.003833673195913434\n",
      "epoch: 48 Loss: 0.00382914572643737\n",
      "epoch: 49 Loss: 0.0038255692925304174\n",
      "epoch: 50 Loss: 0.0038226760613421598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_3636\\2993041711.py:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  pred_data = pred_data.append(pd.DataFrame(preds))\n"
     ]
    }
   ],
   "source": [
    "with tf.compat.v1.Session() as session:\n",
    "    epochs = 50\n",
    "    batch_size = 35\n",
    "\n",
    "    session.run(init)\n",
    "    session.run(local_init)\n",
    "\n",
    "    num_batches = int(user_products_matrix.shape[0] / batch_size)\n",
    "    user_products_matrix = np.array_split(user_products_matrix, num_batches)\n",
    "    \n",
    "    for i in range(epochs):\n",
    "\n",
    "        avg_cost = 0\n",
    "        for batch in user_products_matrix:\n",
    "            _, l = session.run([optimizer, loss], feed_dict={X: batch})\n",
    "            avg_cost += l\n",
    "\n",
    "        avg_cost /= num_batches\n",
    "\n",
    "        print(\"epoch: {} Loss: {}\".format(i + 1, avg_cost))\n",
    "\n",
    "    user_products_matrix = np.concatenate(user_products_matrix, axis=0)\n",
    "\n",
    "    preds = session.run(decoder_op, feed_dict={X: user_products_matrix})\n",
    "\n",
    "    pred_data = pred_data.append(pd.DataFrame(preds))\n",
    "\n",
    "    pred_data = pred_data.stack().reset_index(name='score')\n",
    "    pred_data.columns = ['unique_id', 'product_id', 'score']\n",
    "    pred_data['unique_id'] = pred_data['unique_id'].map(lambda value: users[value])\n",
    "    pred_data['product_id'] = pred_data['product_id'].map(lambda value: products[value])\n",
    "    \n",
    "    keys = ['unique_id', 'product_id']\n",
    "    index_1 = pred_data.set_index(keys).index\n",
    "    index_2 = combined.set_index(keys).index\n",
    "    \n",
    "    top_five_ranked = pred_data[~index_1.isin(index_2)]\n",
    "    top_five_ranked = top_five_ranked.sort_values(['unique_id', 'score'], ascending=[True, False])\n",
    "    top_five_ranked = top_five_ranked.groupby('unique_id').head(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seleccionamos un usuario y vemos la recomendación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'top_five_ranked' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m top_five_ranked\u001b[39m.\u001b[39mloc[top_five_ranked[\u001b[39m'\u001b[39m\u001b[39munique_id\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mf0911a59fdcd8b103c3c87226d8769c5\u001b[39m\u001b[39m'\u001b[39m]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'top_five_ranked' is not defined"
     ]
    }
   ],
   "source": [
    "top_five_ranked.loc[top_five_ranked['unique_id'] == 'f0911a59fdcd8b103c3c87226d8769c5']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d0b213f38fc52db26e82a5fb788bcd7fa62754cf5fb47238d746db968bdcf458"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
